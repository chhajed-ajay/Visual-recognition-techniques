{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BfRONjG1ZWFx"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from matplotlib import pyplot\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.cluster.vq import *\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import sklearn.metrics as metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "rdir_path = './newData'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadDataset():\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    label = -1\n",
        "    \n",
        "    onlyDirs = [f for f in os.listdir(rdir_path) if os.path.isdir(os.path.join(rdir_path, f))]\n",
        "    \n",
        "    for directory in onlyDirs:\n",
        "        label = label + 1\n",
        "        path = rdir_path+'/'+directory\n",
        "        onlyfiles = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
        "        \n",
        "        for file in onlyfiles:\n",
        "            imgPath = path+'/'+file\n",
        "            image = cv.imread(imgPath)\n",
        "            imgs.append(image)\n",
        "            labels.append(label)\n",
        "    \n",
        "    return (imgs,labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "766zdKnYZX_N",
        "outputId": "9022bfa3-2dc8-41a3-fd84-ced126809b0f"
      },
      "outputs": [],
      "source": [
        "# (trainX, trainy), (testX, testy) = cifar10.load_data()\n",
        "dataset = loadDataset()\n",
        "trainX,testX, trainy, testy = train_test_split(dataset[0], dataset[1], \n",
        "                                                train_size=0.75, random_state=42,shuffle = True,stratify = dataset[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BtLQzepTZaH6"
      },
      "outputs": [],
      "source": [
        "def getFeatures(images,labels,method=None):\n",
        "\n",
        "    if method == 'sift':\n",
        "        descriptor = cv.SIFT_create()\n",
        "    elif method == 'surf':\n",
        "        descriptor = cv.SURF_create()\n",
        "\n",
        "    desc_lst=[]\n",
        "    labels_lst = []\n",
        "    cnt = 0\n",
        "    kpts_lst=[]\n",
        "\n",
        "    for img in images:\n",
        "      img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "      #img = cv.resize(img,(150,150),interpolation=cv.INTER_AREA)\n",
        "      kpts, desc = descriptor.detectAndCompute(img,None)\n",
        "      if desc is not None:\n",
        "        desc_lst.append(desc)\n",
        "        kpts_lst.append(kpts)\n",
        "        labels_lst.append(int(labels[cnt]))\n",
        "      cnt = cnt + 1\n",
        "    return kpts_lst,desc_lst,labels_lst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LWJ6yqriZeuc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "kpts_lst,desc_lst,labels_lst = getFeatures(np.concatenate((trainX,testX),axis=0),np.concatenate((trainy,testy)),'sift')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UE8eUyRQZg9P"
      },
      "outputs": [],
      "source": [
        "def getDescriptorStack(desc_lst):\n",
        "  descriptors_stacked = desc_lst[0]\n",
        "  for desc in desc_lst[1:]:\n",
        "    descriptors_stacked = np.vstack((descriptors_stacked,desc))\n",
        "  return descriptors_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZScXFxqyZiwZ"
      },
      "outputs": [],
      "source": [
        "descriptors_lst = getDescriptorStack(desc_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gv6fqMiQZl8u"
      },
      "outputs": [],
      "source": [
        "#k means with k clusters on descriptors_lst\n",
        "k = 80\n",
        "voc,variance = kmeans(descriptors_lst,k,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZPw6rYJgqq1x"
      },
      "outputs": [],
      "source": [
        "imgfeatures = np.zeros((len(labels_lst),k),\"float32\")\n",
        "for i in range(len(labels_lst)):\n",
        "  words,distance = vq(desc_lst[i],voc)\n",
        "  for j in words:\n",
        "    imgfeatures[i][j] +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qSmSLufyqtLN"
      },
      "outputs": [],
      "source": [
        "imgfeatures = StandardScaler().fit_transform(imgfeatures)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pI9UOtoSqvZX"
      },
      "outputs": [],
      "source": [
        "xtrain,xtest,ytrain,ytest = train_test_split(imgfeatures,labels_lst,test_size=0.1,random_state = 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtnJDejbxJH5",
        "outputId": "311ad756-12d1-4404-9ab9-60d76801880f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9444444444444444"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Using the logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0).fit(xtrain, ytrain)\n",
        "ypred = clf.predict(xtest)\n",
        "metrics.accuracy_score(ytest, ypred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VR_Assignment_2a",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
